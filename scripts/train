#!/usr/bin/env python3
import sys
sys.path.append('.')

from graphs import loader
from model import Model

import torch
from torch.nn.functional import log_softmax, kl_div, softmax
from torch.optim import SGD
from torch.utils.tensorboard import SummaryWriter

BATCH_SIZE = 32
LR = 0.0001
MOMENTUM = 0.9
WEIGHT_DECAY = 1e-4
TEMPERATURE = 5

def epoch(writer, model, optimizer, steps):
    optimizer.zero_grad()
    for nodes, adjacency, adjacency_t, indices, y in loader(
        'data/GRP001-1/*.pt'
    ):
        log_real = log_softmax(TEMPERATURE * y, dim=0)
        approximation = model(nodes, adjacency, adjacency_t, indices)
        loss = kl_div(
            log_real.unsqueeze(dim=0),
            approximation.unsqueeze(dim=0),
            reduction='batchmean'
        )
        loss.backward()
        steps += 1
        writer.add_scalar('loss/X-entropy', loss, steps)
        if steps % BATCH_SIZE == 0:
            optimizer.step()
            optimizer.zero_grad()

    optimizer.step()
    optimizer.zero_grad()
    return steps

def train():
    writer = SummaryWriter()
    model = Model().to('cuda')
    optimizer = SGD(
        model.parameters(),
        lr=LR,
        momentum=MOMENTUM,
        weight_decay=WEIGHT_DECAY,
        nesterov=True
    )
    steps = 0
    while True:
        steps = epoch(writer, model, optimizer, steps)
        torch.save(model.state_dict(), 'data/model.pt')

if __name__ == '__main__':
    train()
